#################################
######### INPUT SECTION #########
#################################

# Logstash input listens to port 5045 so that it is able to receive logs coming from Filebeat (beats), from whatever source machine
# Incoming messages are already labelled with an unique identifier, so we do not mind if Logstash receives logs from different sources at the same time
# (we will be able to identify them afterwards thanks to this ID)

input {
        beats {
                port => 5045
        }
}

#################################
######### FILTER SECTION ########
#################################

# Filter section aims to process/treat logs depending on our needs
# In our case, we would like to extract the timestamp field of the logs so that we can then replace such timestamp by the one Kibana sets by default
# In this way, messages will appear temporarily ordered in Kibana, and consequently, this will allow us increasing the number of workers and hence, 
# treating more logs in Logstash in the same period of time

# As shown below in the 'filter {}' block, we have distinguised between tomcat and spring logs by means of the aforementioned ID
# We separate these two types of logs since their formats are different, even the way their timestamp is represented
filter {
	# TOMCAT LOGS (these app_id in the next if statement refer to the log ID)
        if [fields][app_id] == "masterDB_tomcat_logs" or [fields][app_id] == "vacDM_tomcat_logs"
         or [fields][app_id] == "vacMON_tomcat_logs" or [fields][app_id] == "vacCC_tomcat_logs" {
                grok { # grok is a type of filter used by Logstash for extracting fields from raw data. It works with regular expressions, which can be customized
                        patterns_dir => "/etc/logstash/patterns" # path where we have defined our custom regular expressions (file "grok-patterns.txt")
                        match => { "message" => "%{COMMONTOMCATLOG}" } # checking that the incoming log follows the same pattern as our regex (defined in COMMONTOMCATLOG) 
                }
                date {
                        match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ] # checking that our timestamp field matches that specific time Tomcat format 
			target => "timestamp" # this line converts the 'String' timestamp field to a 'date' object, since it is required for the following "mutate" filter  
                }
                mutate { # at this point we have our own timestamp plus the one Kibana gives by default (@timestamp)
                        rename => { "timestamp" => "@timestamp" } # we rename our extracted timestamp with Kibana's timestamp (@timestamp),
								  # so we are basically replacing Kibana's default timestamp field by ours
                        remove_field => ["timestamp"] # we delete our old timestamp field, with one timestamp field is enough
                }
        }
	# SPRING LOGS (these app_id in the next if statement refer to the log ID)
	# Same procedure is followed here, however we need to use a different regex (COMMONSPRINGLOG) defined as well in '/etc/logstash/patterns'
        else if [fields][app_id] == "masterDB_spring_logs" or [fields][app_id] == "vacCC_spring_logs" {
                grok { 
                	patterns_dir => "/etc/logstash/patterns"
                	match => { "message" => "%{COMMONSPRINGLOG}" } 
                }
                date {
                	match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ] # timestamp format changes here
			target => "timestamp"
                }
                mutate {
                	rename => { "timestamp" => "@timestamp" }
                	remove_field => ["timestamp"]
                }
        }
	# SPRING VACMON AND VACDM LOGS (we need to add a new filter type since vacMON and vacDM Spring logs present a different format with respect to masterDB and vacCC Spring logs)
        else if [fields][app_id] == "vacMON_spring_logs" or [fields][app_id] == "vacDM_spring_logs" {
                grok {
                        patterns_dir => "/etc/logstash/patterns"
                        match => { "message" => "%{SPRINGVACMONVACDMLOG}" }
                }
                date {
                        match => [ "timestamp", "dd-MMM-yyyy HH:mm:ss.SSS" ] # timestamp format also changes for vacMON and vacDM Spring logs
                        target => "timestamp"
                }
                mutate {
                        rename => { "timestamp" => "@timestamp" }
                        remove_field => ["timestamp"]
                }
        }	
}

#################################
######### OUTPUT SECTION ########
#################################

# Once our logs have been processed, we are ready to send them to the output, in our case, Elasticsearch (ES) in all our cases
# ES works with indexes. An index is the logical name ES uses for storing data. For simplicity, let us say it is like a "database" 

# You will see below that the difference between each input log file (different app_id therefore), is the index name we have defined, 
# since we want to split data in ES according to the web-application and type of log we are receiving 
# Hence, since we have 8 different app_id identifiers (you can count the number of app_id in both 'if-else' statement in filter section), we would like 
# to create 8 different outputs, each one defining a different index name

# Apart from the index, we also need to set some information regarding credentials and the host we want to connect to
output {
        if [fields][app_id] == "masterDB_spring_logs" {
                elasticsearch { # setting ES as output (the same for the remaining outputs below)
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-masterdb-spring-%{+YYYY.MM}" # specific index name for Spring data coming from masterDB web application
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "masterDB_tomcat_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-masterdb-tomcat-%{+YYYY.MM}" # specific index name for Tomcat data coming from masterDB web application
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "vacDM_spring_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vacdm-spring-%{+YYYY.MM}" # index for Spring data coming from vacDM
                        ilm_enabled => false
                }
        }        
        else if [fields][app_id] == "vacDM_tomcat_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vacdm-tomcat-%{+YYYY.MM}" # index for Tomcat data coming from vacDM
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "vacMON_spring_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vacmon-spring-%{+YYYY.MM}" # index for Spring data coming from vacMON
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "vacMON_tomcat_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vacmon-tomcat-%{+YYYY.MM}" # index for Tomcat data coming from vacMON
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "vacCC_spring_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vaccc-spring-%{+YYYY.MM}" # index for Spring data coming from vacCC
                        ilm_enabled => false
                }
        }
        else if [fields][app_id] == "vacCC_tomcat_logs" {
                elasticsearch {
                        hosts => ['https://es-vacelastic.cern.ch:443/es']
                        user => 'vacelastic'
                        password => 'XXX'
                        cacert => "/etc/pki/tls/certs/CERN-bundle.pem"
                        manage_template => false
                        index => "vacelastic-logs-web-v1-vaccc-tomcat-%{+YYYY.MM}" # index for Tomcat data coming from vacCC
                        ilm_enabled => false
                }
        }
}
